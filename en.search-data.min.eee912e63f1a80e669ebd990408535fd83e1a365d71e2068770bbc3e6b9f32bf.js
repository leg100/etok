'use strict';(function(){const b={cache:!0};b.doc={id:'id',field:['title','content'],store:['title','href','section']};const a=FlexSearch.create('balance',b);window.bookSearchIndex=a,a.add({id:0,href:'/docs/reference/commands/terraform/',title:"Terraform",section:"Commands",content:"Supported Terraform Commands #  Most terraform commands are supported. A (Q) means it is a queueable command.\n apply(Q) console destroy(Q) fmt force-unlock(Q) get graph import(Q) init(Q) output plan providers providers lock refresh(Q) state list state mv(Q) state pull state push(Q) state replace-provider(Q) state rm(Q) state show show taint(Q) untaint(Q) validate  Ensure terraform flags follow a double dash:\netok apply -- -auto-approve   "}),a.add({id:1,href:'/docs/reference/operator_install/',title:"Operator Install",section:"Reference",content:"Operator Install #  The command etok install installs the operator component onto the cluster.\nIt will perform an upgrade if it is already installed. This can also be useful for making configuration changes to an existing installation.\nBy default, it\u0026rsquo;ll use the namespace etok. It\u0026rsquo;ll create the namespace if it doesn\u0026rsquo;t already exist. To use a non-default namespace, pass the --namespace flag.\nRun the version command to retrieve the currently installed operator version:\n\u0026gt; etok version This\u0026rsquo;ll print out both the version and the git commit of both the client and operator components, like so:\nClient Version: 0.0.9	adf6e514340e49ba98dc86574990a488b2335965 Server Version: 0.0.9	adf6e514340e49ba98dc86574990a488b2335965 (Server refers to the operator component)\n"}),a.add({id:2,href:'/docs/background/configuration_upload/',title:"Configuration Upload",section:"Background",content:"What is uploaded to the pod when running a command? #  The contents of the root module (the current working directory, or the value of the path flag) is uploaded. Additionally, if the root module configuration contains references to other modules on the local filesystem, then these too are uploaded, along with all such modules recursively referenced (modules referencing modules, and so forth). The directory structure of your git repository is maintained on the kubernetes pod, ensuring relative references remain valid (e.g. ./modules/vpc or ../modules/vpc).\nEtok supports the use of a .terraformignore file. Etok expects to find the file at the root of your git repository. If not found then the default set of rules apply:\n .git/ directories .terraform/ directories, exclusive of .terraform/modules  "}),a.add({id:3,href:'/docs/background/performance_optimization/',title:"Performance Optimization",section:"Background",content:"How do I optimize performance? #  You can reasonably expect commands to start running in less than a couple of seconds. That depends on several factors.\nMinimize upload of data. As documented above, use a .terraformignore file to skip files you don\u0026rsquo;t need to upload. Pass the flag -v=3 to see which files are being uploaded and which are ignored.\nDisable TTY. Pass the --no-tty flag to the command. By default, if a TTY is detected, Etok performs a handshake with the pod which adds a delay. However, disabling TTY means you cannot enter standard input if prompted. Disabling TTY generally shaves off 500-1000ms.\nUse fast persistent volume storage class for workspace cache. If you\u0026rsquo;re using GKE, pass --storage-class=premium-rwo when creating a new workspace with workspace new.\nAlso, if you\u0026rsquo;re using GKE, configure the cluster to use the CSI driver. Anecdotal experience suggests it\u0026rsquo;s faster than the in-tree persistent volume driver.\n"}),a.add({id:4,href:'/docs/guides/state_backup/',title:"State Backup",section:"Guides",content:"State Backup and Restore #  Backup of state to cloud storage is supported. If enabled, every update to state is backed up to a cloud storage bucket. When a new workspace is created, the operator checks if a backup exists. If so, it is restored.\nSetup Cloud Storage #  First follow instructions for configuring backups for either GCS or S3:\nGCS   Create a GCS bucket:\ngsutil mb gs://my-backup-bucket   Provide the etok operator with the necessary privileges.\na. Either create a secret containing a service account key, or setup workload identity.\nb. Ensure the service account possesses the following IAM permissions on the bucket:\nstorage.buckets.get storage.objects.create storage.objects.delete storage.objects.get   Install/update the operator, configuring it to use the GCS backup provider, and providing the name of the bucket:\netok install --backup-provider=gcs --gcs-bucket=backups-bucket If you\u0026rsquo;re using Workload Identity then you\u0026rsquo;ll need to set the service account annotation too:\netok install --backup-provider=gcs --gcs-bucket=backups-bucket \\  --sa-annotations iam.gke.io/gcp-service-account=[GSA_NAME]@[PROJECT_NAME].iam.gserviceaccount.com   S3   Create an S3 bucket:\naws s3 mb s3://my-backup-bucket --region eu-west-2   Provide the etok operator with the necessary privileges.\na. Create a secret containing an AWS access key and secret key.\nb. Ensure the keys belong to a user that can access the bucket. The following IAM policy provides the necessary permissions:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::${BACKUP_BUCKET}/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::${BACKUP_BUCKET}\u0026#34; ] } ] }   Install/update the operator, configuring it to use the S3 backup provider, providing the name of the bucket and the bucket\u0026rsquo;s region:\netok install --backup-provider=s3 --s3-bucket=backups-bucket --s3-region=eu-west-2    Testing Backup #  Now you can check that your terraform state is successfully backed up:\n  Create a workspace if you haven\u0026rsquo;t already:\netok workspace new foo   Initialize the terraform state:\netok init   Retrieve workspace status and events:\nkubectl describe ws foo ... Terraform Version: 0.14.3 Status: Backup Serial: 2 Conditions: Last Transition Time: 2021-02-15T12:19:10Z Message: Reason: AllSystemsOperational Status: True Type: Ready Phase: ready Serial: 2 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal RestoreSkipped 9m32s (x14 over 15m) workspace-controller There is no state to restore Normal BackupSuccessful 9m28s workspace-controller Backed up state #0 Normal BackupSuccessful 83s workspace-controller Backed up state #1 Normal BackupSuccessful 25s workspace-controller Backed up state #2 If Backup Serial and Serial both refer to the same serial number then the most recent version of the state has been successfully backed up.\n  Testing Restore #  To check that state can be restored follow these steps:\n  Delete the workspace we previously worked with:\netok workspace delete foo That deletes the kubernetes secret containing its state.\n  Now re-create the workspace with the same name:\netok workspace new foo   Retrieve workspace status and events:\nkubectl describe ws foo ... Terraform Version: 0.14.3 Status: Backup Serial: 2 Conditions: Last Transition Time: 2021-02-15T12:56:41Z Message: Reason: AllSystemsOperational Status: True Type: Ready Phase: ready Serial: 2 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal RestoreSuccessful 35s workspace-controller Restored state #2 Which should indicate the state has been successfully restored.\n  Opt-out #  To opt a workspace out of automatic backup and restore, pass the --ephemeral flag when creating a new workspace with workspace new. This is useful if you intend for your workspace to be short-lived.\n"}),a.add({id:5,href:'/docs/reference/access_control/',title:"Access Control",section:"Reference",content:"Access Control #  The install command installs ClusterRoles (and ClusterRoleBindings) for your convenience:\n etok-user: includes the permissions necessary for running unprivileged commands etok-admin: additional permissions for managing workspaces and running privileged commands  Amend the bindings accordingly to add/remove users. For example to amend the etok-user binding:\nkubectl edit clusterrolebinding etok-user Note: To restrict users to individual namespaces you\u0026rsquo;ll want to create RoleBindings referencing the ClusterRoles.\n"}),a.add({id:6,href:'/docs/reference/commands/',title:"Commands",section:"Reference",content:"Commands #  Most terraform commands are supported.\nThere are some useful additional commands as well.\nPrivileged Commands #  Commands can be specified as privileged. Only users possessing the RBAC permission to update the workspace can run privileged commands. Specify them via the --privileged-commands flag when creating a new workspace with workspace new.\nQueueable Commands (Q) #  Commands with the ability to alter state are deemed \u0026lsquo;queueable\u0026rsquo;: only one queueable command at a time can run on a workspace. The currently running command is designated as \u0026lsquo;active\u0026rsquo;, and commands waiting to become active wait in a workspace FIFO queue.\nAll other commands run immediately and concurrently.\n"}),a.add({id:7,href:'/docs/reference/commands/additional/',title:"Additional",section:"Commands",content:"Additional Commands #   sh(Q) - run shell or arbitrary command in workspace  "}),a.add({id:8,href:'/docs/reference/credentials/',title:"Credentials",section:"Reference",content:"Credentials #  The operator as well as commands may require credentials. The operator may require credentials for performing state backups to cloud storage. And commands such as plan and apply may require credentials for using various terraform providers such as for AWS or GCP.\nIt\u0026rsquo;s advisable where possible to adopt approaches such as Workload Identity instead. They avoid the need to use credentials, thereby also avoiding the associated overhead and security risks, such as manual rotation, ensuring they are not printed in output, etc.  Etok looks for credentials in a secret named etok. The secret needs to be in the relevant namespace: the operator will look for the secret etok/etok (if the default etok namespace is used); whereas a command will look for the secret in the namespace of its workspace. For instance if its workspace is in the dev namespace, then the command will look for the secret dev/etok.\nThe credentials are made available to the running process as environment variables. The key is the environment variable name, and the corresponding value is the environment variable value.\nFor instance to set credentials for the Terraform GCP provider, or for making backups to GCS:\nkubectl create secret generic etok --from-file=GOOGLE_CREDENTIALS=[path to service account key] Or, to set credentials for the AWS provider, or for making backups to S3:\nkubectl create secret generic etok \\  --from-literal=AWS_ACCESS_KEY_ID=\u0026#34;youraccesskeyid\u0026#34; \\  --from-literal=AWS_SECRET_ACCESS_KEY=\u0026#34;yoursecretaccesskey\u0026#34; "}),a.add({id:9,href:'/docs/reference/restrictions/',title:"Restrictions",section:"Reference",content:"Restrictions #  Both the terraform configuration and the terraform state, after compression, are subject to a 1MiB limit. This due to the fact that they are stored in a config map and a secret respectively, and the data stored in either cannot exceed 1MiB.\n"}),a.add({id:10,href:'/docs/reference/state/',title:"State",section:"Reference",content:"State #  Terraform state is stored in a secret using the kubernetes backend. It comes into existence once you run etok init. If the workspace is deleted then so is the state.\nDo not define a backend in your terraform configuration - it will conflict with the configuration Etok automatically installs.  "}),a.add({id:11,href:'/docs/reference/testing/',title:"Testing",section:"Reference",content:"E2E Tests #  Run the following make task to run a battery of end-to-end tests against a running kubernetes cluster:\nmake e2e One or more environment variables need to be specified:\n BACKUP_BUCKET - GCS bucket to backup state to during the tests  By default the tests assume you\u0026rsquo;re running kind. For tests targeting kind you need to also specify:\n GOOGLE_APPLICATION_CREDENTIALS - Path to a file containing a service account key with credentials to read and write to $BACKUP_BUCKET  To target a GKE cluster, set ENV=gke along with:\n BACKUP_SERVICE_ACCOUNT - GCP service account with permissions to read and write to $BACKUP_BUCKET GKE_IMAGE - Name to assign to the docker image that is built and pushed, e.g. eu.gcr.io/my-project/etok GKE_KUBE_CONTEXT - Name of the kubectl context for the GKE cluster  Because the GKE tests use workload identity, you need to set an IAM policy on $BACKUP_SERVICE_ACCOUNT.\n"}),a.add({id:12,href:'/docs/tutorials/getting_started/',title:"Getting Started",section:"Tutorials",content:"Getting Started #  This tutorial will guide you through installing and running etok for the first time.\nYou\u0026rsquo;re expected to be familiar with both terraform and kubernetes.\nKubernetes Cluster #  Firstly ensure you have access to a kubernetes cluster. If you don\u0026rsquo;t have access to a cluster then you might want to install kind, a tool for locally running a cluster in a docker container.\nAlso, in order to install etok, ensure you have extensions permissions on the cluster.\nInstall #  Download etok from releases. Extract the etok binary from the zipfile and copy it to a directory in your PATH, such as /usr/local/bin.\nEtok is composed of two components: the operator (or server), which runs on the cluster, and the client (or CLI), which runs on your workstation.\nThe operator first needs to be installed. To do so run the following command:\netok install You should see output related to the the installation:\nCreating resource CustomResourceDefinition workspaces.etok.dev Creating resource CustomResourceDefinition runs.etok.dev Creating resource ClusterRole etok Creating resource ClusterRole etok-user Creating resource ClusterRole etok-admin Creating resource ClusterRoleBinding etok Creating resource ClusterRoleBinding etok-user Creating resource ClusterRoleBinding etok-admin Creating resource Namespace etok Creating resource ServiceAccount etok/etok Creating resource Deployment etok/etok Waiting for Deployment to be ready It may take up to several minutes to install. The resources are installed into the etok namespace.\nAny problems can be diagnosed using kubectl. To check the status of the deployment run the following command:\nkubectl --namespace=etok get deploy You can also check the versions of the currently deployed components by running the following command:\n\u0026gt; etok version This\u0026rsquo;ll print out both the version and the git commit of the respective components, like so:\nClient Version: 0.0.9	adf6e514340e49ba98dc86574990a488b2335965 Server Version: 0.0.9	adf6e514340e49ba98dc86574990a488b2335965 (Server refers to the operator component)\nOnce installed you can proceed to creating your first workspace.\nFirst Workspace #  An etok workspace is much the same as a terraform workspace. Unlike terraform, there is no default workspace and a workspace must first be created before you can run terraform commands.\nRun the following command to create a workspace named dev:\netok workspace new dev You should see output similar to the following:\nCreated workspace default/dev Waiting for workspace pod to be ready... Requested terraform version is 0.14.3 Current terraform version is 0.14.3 Skipping terraform installation If there are problems you can again help diagnose them using kubectl. The check the status of the workspace, run:\nkubectl get ws If all is well then you should see the following:\nNAME PHASE VERSION AGE ACTIVE QUEUE dev ready 0.14.3 113s First Terraform Run #  Now you\u0026rsquo;re ready to run a terraform command. Ensure you\u0026rsquo;re still in the same directory as the one in which you created the workspace.\nFirst, write some terraform configuration. Add the following in a new file named random.tf:\nresource \u0026#34;random_id\u0026#34; \u0026#34;test\u0026#34; { byte_length = 2 } Now run the init command:\netok init This command creates a new kubernetes pod, uploads random.tf and runs terraform init on the pod. And then it\u0026rsquo;ll stream the output to the client:\nInitializing the backend... Successfully configured the backend \u0026#34;kubernetes\u0026#34;! Terraform will automatically use this backend unless the backend configuration changes. Initializing provider plugins... - Finding latest version of hashicorp/random... - Installing hashicorp/random v3.0.1... - Installed hashicorp/random v3.0.1 (signed by HashiCorp) Terraform has created a lock file .terraform.lock.hcl to record the provider selections it made above. Include this file in your version control repository so that Terraform can guarantee to make the same selections by default when you run \u0026#34;terraform init\u0026#34; in the future. Terraform has been successfully initialized! You may now begin working with Terraform. Try running \u0026#34;terraform plan\u0026#34; to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. If there are any problems, run kubectl to retrieve information about the run:\nkubectl get run It should provide output similar to the following:\nNAME COMMAND WORKSPACE PHASE AGE run-w6nc4 init dev completed 11m run-w6nc4 is the unique ID of the run. You can use this to probe for more information, for instance to retrieve information about the run\u0026rsquo;s pod:\nkubectl describe pod run-w6nc4 You can now proceed to running further terraform commands.\nTerraform Plan and Apply #  Having run init you can now run a plan:\netok plan This should output:\nAn execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # random_id.test will be created + resource \u0026#34;random_id\u0026#34; \u0026#34;test\u0026#34; { + b64_std = (known after apply) + b64_url = (known after apply) + byte_length = 2 + dec = (known after apply) + hex = (known after apply) + id = (known after apply) } Plan: 1 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ Note: You didn\u0026#39;t specify an \u0026#34;-out\u0026#34; parameter to save this plan, so Terraform can\u0026#39;t guarantee that exactly these actions will be performed if \u0026#34;terraform apply\u0026#34; is subsequently run. Again you can use kubectl to diagnose any issues:\nkubectl get run Which should show information about both runs:\nNAME COMMAND WORKSPACE PHASE AGE run-ir7wb plan dev completed 88s run-w6nc4 init dev completed 21m If the plan succeeded you can now run an apply:\netok apply This\u0026rsquo;ll print out the usual terraform output, and prompt for confirmation:\nAn execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # random_id.test will be created + resource \u0026#34;random_id\u0026#34; \u0026#34;test\u0026#34; { + b64_std = (known after apply) + b64_url = (known after apply) + byte_length = 2 + dec = (known after apply) + hex = (known after apply) + id = (known after apply) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only \u0026#39;yes\u0026#39; will be accepted to approve. Enter a value: yes random_id.test: Creating... random_id.test: Creation complete after 0s [id=kOM] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Next Steps #  You should now be comfortable with basic usage of etok. However to appreciate its advantages (versus running terraform on your workstation) you\u0026rsquo;ll want to read the documentation further, in particular with regard to RBAC, configuring privileged commands, and the handling of credentials.\n"}),a.add({id:13,href:'/docs/background/crds/',title:"CRDs",section:"Background",content:"CRDs #  Etok uses two CRDs (custom resource definitions):\n Run Workspace  Run #  Whenever you run a terraform command with etok, a Run resource is created:\n\u0026gt; etok plan \u0026gt; kubectl get run NAME COMMAND WORKSPACE PHASE AGE run-290w7 plan dev completed 12s Workspace #  A Workspace resource maps to a terraform workspace. The command etok workspace new is a convenience method for creating a Workspace resource:\n\u0026gt; etok workspace new foo \u0026gt; kubectl get ws NAME PHASE VERSION AGE ACTIVE QUEUE foo ready 0.14.3 22s "}),a.add({id:14,href:'/docs/guides/workload_identity/',title:"Workload Identity",section:"Guides",content:"Workload Identity #  Workload Identity lets GKE pods assume privileges to Google Cloud without the use of credentials. Etok can use Workload Identity both for terraform and for the operator: terraform can use it to authorize the Google Cloud provider to manage Google Cloud resources; the operator can use it to perform state backups.\nTerminology #  With Workload Identity, you configure a Kubernetes service account to act as a Google service account. The following acronyms will be used to clearly differentiate between the two types of service account:\n KSA: Kubernetes Service Account GSA: Google Service Account  Guide #  This guide provides instructions for setting up workload identity both for terraform and for state backups.\nTerraform   Ensure your GKE cluster has Workload Identity enabled.\n  Create a GSA if you haven\u0026rsquo;t got one already:\ngcloud iam service-accounts create GSA_NAME   Grant IAM privileges to the GSA. For example, assign the compute engine admin IAM role to permit terraform apply to create VMs in a Google Cloud project via the google_compute_instance resource:\ngcloud projects add-iam-policy-binding [PROJECT_ID] \\  --member=serviceAccount:[GSA_EMAIL] --role roles/compute.admin   You now need to determine the KSA to use. Etok configures pods with a KSA named etok in the given namespace. For instance, if your workspace is in the namespace dev, then any terraform commands you run on that workspace will use the KSA dev/etok. When you create a workspace for the first time in a namespace, a KSA named etok is automatically created. If you haven\u0026rsquo;t yet created a workspace, then you can manually create the KSA:\nkubectl create serviceaccount etok --namespace [NAMESPACE] To allow the KSA to impersonate the GSA, create an IAM policy between the two:\ngcloud iam service-accounts add-iam-policy-binding \\  --role roles/iam.workloadIdentityUser \\  --member \u0026#34;serviceAccount:[PROJECT_ID].svc.id.goog[NAMESPACE/etok]\u0026#34; \\  [GSA_NAME]@[GSA_PROJECT_ID].iam.gserviceaccount.com Where PROJECT_ID is the project of the GKE cluster, NAMESPACE is the namespace of the KSA named etok, and GSA_PROJECT_ID is the project of the GSA.\n  Annotate the KSA with details of the GSA it is impersonating:\nkubectl annotate serviceaccounts --namespace [NAMESPACE] etok \\  iam.gke.io/gcp-service-account=[GSA_NAME]@[PROJECT_ID].iam.gserviceaccount.com   Create a workspace if you haven\u0026rsquo;t already:\netok workspace new --namespace NAMESPACE WORKSPACE_NAME   Write some terraform configuration to deploy a VM in Google Cloud:\nresource \u0026#34;google_compute_instance\u0026#34; \u0026#34;default\u0026#34; { name = \u0026#34;test\u0026#34; machine_type = \u0026#34;e2-medium\u0026#34; zone = \u0026#34;europe-west2-a\u0026#34; project = \u0026#34;[PROJECT_ID]\u0026#34; boot_disk { initialize_params { image = \u0026#34;debian-cloud/debian-9\u0026#34; } } network_interface { network = \u0026#34;default\u0026#34; access_config {// Ephemeral IP  } } }   Run etok init:\netok init Initializing the backend... Successfully configured the backend \u0026#34;kubernetes\u0026#34;! Terraform will automatically use this backend unless the backend configuration changes. Initializing provider plugins... - Reusing previous version of hashicorp/random from the dependency lock file - Finding latest version of hashicorp/google... - Installing hashicorp/google v3.56.0... - Installed hashicorp/google v3.56.0 (signed by HashiCorp) - Installing hashicorp/random v3.0.1... - Installed hashicorp/random v3.0.1 (signed by HashiCorp) Terraform has made some changes to the provider dependency selections recorded in the .terraform.lock.hcl file. Review those changes and commit them to your version control system if they represent changes you intended to make. Terraform has been successfully initialized! You may now begin working with Terraform. Try running \u0026#34;terraform plan\u0026#34; to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary.   Run etok apply:\netok apply An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # google_compute_instance.default will be created + resource \u0026#34;google_compute_instance\u0026#34; \u0026#34;default\u0026#34; { + can_ip_forward = false + cpu_platform = (known after apply) + current_status = (known after apply) + deletion_protection = false + guest_accelerator = (known after apply) + id = (known after apply) + instance_id = (known after apply) + label_fingerprint = (known after apply) + machine_type = \u0026#34;e2-medium\u0026#34; + metadata_fingerprint = (known after apply) + min_cpu_platform = (known after apply) + name = \u0026#34;test\u0026#34; + project = \u0026#34;automatize-admin\u0026#34; + self_link = (known after apply) + tags_fingerprint = (known after apply) + zone = \u0026#34;europe-west2-a\u0026#34; + boot_disk { + auto_delete = true + device_name = (known after apply) + disk_encryption_key_sha256 = (known after apply) + kms_key_self_link = (known after apply) + mode = \u0026#34;READ_WRITE\u0026#34; + source = (known after apply) + initialize_params { + image = \u0026#34;debian-cloud/debian-9\u0026#34; + labels = (known after apply) + size = (known after apply) + type = (known after apply) } } + confidential_instance_config { + enable_confidential_compute = (known after apply) } + network_interface { + name = (known after apply) + network = \u0026#34;default\u0026#34; + network_ip = (known after apply) + subnetwork = (known after apply) + subnetwork_project = (known after apply) + access_config { + nat_ip = (known after apply) + network_tier = (known after apply) } } + scheduling { + automatic_restart = (known after apply) + on_host_maintenance = (known after apply) + preemptible = (known after apply) + node_affinities { + key = (known after apply) + operator = (known after apply) + values = (known after apply) } } } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only \u0026#39;yes\u0026#39; will be accepted to approve. Enter a value: yes google_compute_instance.default: Creating... google_compute_instance.default: Still creating... [10s elapsed] google_compute_instance.default: Creation complete after 14s [id=projects/automatize-admin/zones/europe-west2-a/instances/test] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. This demonstrates terraform has been able to use the privileges conferred by workload identity.\n  Backups   Ensure your GKE cluster has Workload Identity enabled.\n  Create a GSA if you haven\u0026rsquo;t got one already:\ngcloud iam service-accounts create GSA_NAME   Grant sufficient IAM privileges to the GSA on the GCS bucket you\u0026rsquo;ll use for backups. See the state backups guide for the exact permissions.\n  Allow the etok operator KSA to impersonate the GSA, create an IAM policy between the two:\ngcloud iam service-accounts add-iam-policy-binding \\  --role roles/iam.workloadIdentityUser \\  --member \u0026#34;serviceAccount:[PROJECT_ID].svc.id.goog[etok/etok]\u0026#34; \\  [GSA_NAME]@[GSA_PROJECT_ID].iam.gserviceaccount.com [etok/etok] refers to the KSA named etok in the namespace etok, which is the default for the operator install. PROJECT_ID is the project of the GKE cluster, and GSA_PROJECT_ID is the project of the GSA.\n  Now follow the state backups guide to install or upgrade the operator with necessary backup provider configuration as well as the necessary service account annotation to complete the configuration of workoad identity for backups.\n   "})})()